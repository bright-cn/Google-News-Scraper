# Google æ–°é—»æŠ“å–å™¨
æœ¬ä»“åº“æä¾›ä¸¤ç§ä» Google æ–°é—»æ”¶é›†æ•°æ®çš„æ–¹æ³•ã€‚  
- **å…è´¹æ–¹æ³•ï¼š** é€‚ç”¨äºå°å‹é¡¹ç›®å’Œå­¦ä¹   
- **Google æ–°é—» APIï¼š** é€‚åˆå¤§è§„æ¨¡ã€å¯é çš„å®æ—¶æ•°æ®æå–

## ç›®å½•

- [æ–¹æ³•ä¸€ï¼šå…è´¹ Google æ–°é—»æŠ“å–å™¨](#æ–¹æ³•ä¸€å…è´¹-google-æ–°é—»æŠ“å–å™¨)
  - [å…ˆå†³æ¡ä»¶](#å…ˆå†³æ¡ä»¶)
  - [å®‰è£…](#å®‰è£…)
  - [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)
  - [è¾“å‡ºç»“æœ](#è¾“å‡ºç»“æœ)
- [å¸¸è§æŠ“å–æŒ‘æˆ˜](#å¸¸è§æŠ“å–æŒ‘æˆ˜)
- [æ–¹æ³•äºŒï¼šBright Data Google æ–°é—» API](#æ–¹æ³•äºŒbright-data-google-æ–°é—»-api)
  - [ä¸»è¦ä¼˜åŠ¿](#ä¸»è¦ä¼˜åŠ¿)
  - [Google æ–°é—» API å…¥é—¨æŒ‡å—](#google-æ–°é—»-api-å…¥é—¨æŒ‡å—)
  - [å…³é”®è¾“å…¥å‚æ•°](#å…³é”®è¾“å…¥å‚æ•°)
  - [ç¤ºä¾‹ç»“æœ](#ç¤ºä¾‹ç»“æœ)
  - [å¯ç›´æ¥ä½¿ç”¨çš„ Python ä»£ç ](#å¯ç›´æ¥ä½¿ç”¨çš„-python-ä»£ç )
  - [ç†è§£ API çš„å®ç°æ–¹å¼](#ç†è§£-api-çš„å®ç°æ–¹å¼)
  - [è‡ªå®šä¹‰æ‚¨çš„æ•°æ®æ”¶é›†](#è‡ªå®šä¹‰æ‚¨çš„æ•°æ®æ”¶é›†)

## æ–¹æ³•ä¸€ï¼šå…è´¹ Google æ–°é—»æŠ“å–å™¨
<img width="700" alt="image" src="https://github.com/bright-cn/Google-News-Scraper/assets/a7d34ffe-17c6-4c59-acbf-aaf84ed1b13e">

æ­¤å…è´¹å·¥å…·å¯æ ¹æ®æ‚¨æ„Ÿå…´è¶£çš„ä»»æ„ä¸»é¢˜æ”¶é›†æ–°é—»æ–‡ç« æ•°æ®ã€‚æ‚¨å°†è·å¾—ä»æ ‡é¢˜åˆ°å‘å¸ƒæ—¥æœŸçš„å„ç§ä¿¡æ¯ï¼Œå¹¶æ•´é½åœ°ç»„ç»‡èµ·æ¥ã€‚

### å…ˆå†³æ¡ä»¶
- Python 3.9+
- ä¸¤ä¸ªä¸»è¦ä¾èµ–åŒ…ï¼š
  - [aiohttp](https://pypi.org/project/aiohttp/)ï¼ˆç”¨äºå‘é€è¯·æ±‚ï¼‰
  - [beautifulsoup4](https://pypi.org/project/beautifulsoup4/)ï¼ˆç”¨äºè§£æ HTMLï¼‰

### å®‰è£…
1. å…‹éš†æ­¤ä»“åº“ï¼š

    ```bash
    git clone https://github.com/bright-cn/Google-News-Scraper.git
    ```
2. è¿›å…¥é¡¹ç›®ç›®å½•ï¼š

    ```bash
    cd Google-News-Scraper
    ```
3. å®‰è£…æ‰€éœ€ä¾èµ–é¡¹ï¼š

    ```bash
    pip install -r requirements.txt
    ```

### ä½¿ç”¨æ–¹æ³•
1. å‰å¾€ `free_scraper` ç›®å½•å¹¶æ‰“å¼€ `main.py`
2. åœ¨æ–‡ä»¶ä¸­å®šä¹‰æ‚¨çš„æœç´¢å…³é”®è¯ï¼š

    ```bash
    search_terms = [
        "artificial intelligence",
        "climate change",
        "space exploration",
        # æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šæœç´¢è¯
    ]
    ```
3. è¿è¡ŒæŠ“å–ç¨‹åºï¼š

    ```bash
    python main.py
    ```

### è¾“å‡ºç»“æœ
æŠ“å–å™¨å°†ç”Ÿæˆ JSON æ–‡ä»¶ï¼š  
- é’ˆå¯¹æ¯ä¸ªæœç´¢è¯çš„ç‹¬ç«‹ JSON æ–‡ä»¶  
- åŒ…å«æ‰€æœ‰æœç´¢è¯æ•°æ®çš„ `combined_results.json` æ–‡ä»¶

æ¯ç¯‡æ–‡ç« åœ¨ JSON è¾“å‡ºä¸­åŒ…å«ä»¥ä¸‹å†…å®¹ï¼š
```json
{
    "title": "OpenAI launches full o1 model with image uploads and analysis, debuts ChatGPT Pro - VentureBeat",
    "link": "https://news.google.com/rss/articles/CBMipgFBVV95cUxQTTVmS1I4aW1QanZXTnBfa2tBR3d0Y2JzNjJJNldBZTd1TVVfRmpxaUM3bGJld3RycXhPbU8wM1loT0JGd2JDRzFmU1pLU3FSbkRRZ0FPY29INmdhU1RsWXFqXzdLTjNCbU5ES3pIQXZLbTVmMWVhc0FqVlljeWNPOHZMeFlXV2F5Q21ac0lSZVhIOHlnS05sdkR5ZjhJTU9HazJ6MWJR?oc=5",
    "publication_date": "Thu, 05 Dec 2024 18:00:00 GMT",
    "source": "VentureBeat",
    "source_url": "https://venturebeat.com",
    "guid": "CBMipgFBVV95cUxQTTVmS1I4aW1QanZXTnBfa2tBR3d0Y2JzNjJJNldBZTd1TVVfRmpxaUM3bGJld3RycXhPbU8wM1loT0JGd2JDRzFmU1pLU3FSbkRRZ0FPY29INmdhU1RsWXFqXzdLTjNCbU5ES3pIQXZLbTVmMWVhc0FqVlljeWNPOHZMeFlXV2F5Q21ac0lSZVhIOHlnS05sdkR5ZjhJTU9HazJ6MWJR"
}
```

ğŸ‘‰ æ‚¨å¯ä»¥åœ¨æˆ‘ä»¬çš„ [free_scraper/data/](https://github.com/bright-cn/Google-News-Scraper/tree/main/free_scraper/data) ç›®å½•ä¸­æ‰¾åˆ°å®Œæ•´çš„ç¤ºä¾‹è¾“å‡ºã€‚

## å¸¸è§æŠ“å–æŒ‘æˆ˜
ä» Google æ–°é—»æŠ“å–æ•°æ®å¯èƒ½ç›¸å½“å…·æœ‰æŒ‘æˆ˜æ€§ã€‚ä»¥ä¸‹æ˜¯æ‚¨å¯èƒ½é‡åˆ°çš„ä¸€äº›å¸¸è§é—®é¢˜ï¼š  
1. **éªŒè¯ç å’Œé˜²æœºå™¨äººæœºåˆ¶ï¼š** Google é€šå¸¸ä¼šä½¿ç”¨éªŒè¯ç æˆ–é™é€Ÿæœºåˆ¶æ¥é˜»æ­¢æœºå™¨äººè®¿é—®å…¶å†…å®¹ã€‚  
2. **å¯æ‰©å±•æ€§ï¼š** å¯¹å¤§é‡æ•°æ®æˆ–é«˜é¢‘ç‡è¿›è¡ŒæŠ“å–ä¼šè®©å…è´¹æŠ“å–å™¨ä¸å ªé‡è´Ÿã€‚  
3. **å…¨çƒå’Œæœ¬åœ°åŒ–æ–°é—»è·å–ï¼š** ä¸ºä¸åŒåœ°åŒºå’Œè¯­è¨€å®šåˆ¶æŠ“å–å™¨é€šå¸¸éœ€è¦å¤§é‡çš„åŠªåŠ›å’Œäººå·¥è°ƒæ•´ã€‚

## æ–¹æ³•äºŒï¼šBright Data Google æ–°é—» API
æƒ³è¦æ›´ç¨³å¥çš„æ–¹æ¡ˆå—ï¼Ÿè®©æˆ‘ä»¬æ¥è°ˆè°ˆ [Bright Data çš„ Google æ–°é—» API](https://bright.cn/products/serp-api/google-search/news)ã€‚ä»¥ä¸‹æ˜¯å®ƒå€¼å¾—è€ƒè™‘çš„åŸå› ï¼š

### ä¸»è¦ä¼˜åŠ¿
- **æ— éœ€åŸºç¡€è®¾æ–½çƒ¦æ¼ï¼š** ä¸ç”¨å†ä¸ºä»£ç†å’ŒéªŒè¯ç çƒ¦å¿ƒ
- **ä¸ºæ‰©å±•è€Œç”Ÿï¼š** åœ¨é«˜æµé‡ä¸‹ä»è¡¨ç°ä¼˜å¼‚
- **å…¨çƒè¦†ç›–ï¼š** å¯è·å–æ¥è‡ªä»»ä½•å›½å®¶ã€ä»»ä½•è¯­è¨€çš„æ–°é—»
- **éšç§ä¼˜å…ˆï¼š** ç¬¦åˆ GDPR & CCPA è¦æ±‚
- **æŒ‰æˆåŠŸä»˜è´¹ï¼š** ä»…å¯¹æˆåŠŸè¯·æ±‚æ”¶è´¹
- **è¯•ç”¨å†è´­ä¹°ï¼š** æä¾› 20 æ¬¡å…è´¹ API è°ƒç”¨æµ‹è¯•

## å¼€å§‹ä½¿ç”¨ Google æ–°é—» API
> å¦‚éœ€äº†è§£è®¾ç½® Google æ–°é—» API çš„è¯¦ç»†æ­¥éª¤ï¼Œè¯·æŸ¥çœ‹æˆ‘ä»¬çš„ [åˆ†æ­¥è®¾ç½®æŒ‡å—](https://github.com/bright-cn/Google-News-Scraper/blob/main/google_news_api_setup.md)ã€‚

### å…³é”®è¾“å…¥å‚æ•°
| **å‚æ•°**      | **å¿…éœ€ï¼Ÿ** | **æè¿°**                | **ç¤ºä¾‹**              |
|---------------|------------|-------------------------|-----------------------|
| `url`         | æ˜¯         | åŸºæœ¬çš„ Google æ–°é—» URL  | `news.google.com`     |
| `keyword`     | æ˜¯         | æ‚¨çš„æœç´¢ä¸»é¢˜            | `"ChatGPT"`           |
| `country`     | å¦         | è·å–æ–°é—»çš„å›½å®¶          | `"US"`                |
| `language`    | å¦         | æ‚¨æƒ³è¦çš„è¯­è¨€            | `"en"`                |

### ç¤ºä¾‹ç»“æœ
ä»¥ä¸‹æ˜¯ API è¿”å›çš„ç»“æœç¤ºä¾‹ï¼š  
```json
{
    "url": "https://www.tomsguide.com/news/live/12-days-of-openai-live-blog-chatgpt-sora",
    "title": "12 Days of OpenAI Day 2 LIVE: o1 full is here and every new ChatGPT AI announcement as it happens",
    "publisher": "Tom's Guide",
    "date": "2024-12-06T20:54:01.000Z",
    "category": null,
    "keyword": "chatgpt",
    "country": "US",
    "image": "https://news.google.com/api/attachments/CC8iK0NnNW9SbTFVTWtkNGFGSjJSVGhGVFJDb0FSaXNBaWdCTWdhQmtJcWpOQWM=-w200-h112-p-df-rw",
    "timestamp": "2024-12-08T10:06:05.122Z",
    "input": {
        "url": "https://news.google.com/",
        "keyword": "chatgpt",
        "country": "US",
        "language": "en"
    }
}
```
ğŸ‘‰ æ‚¨å¯ä»¥åœ¨æˆ‘ä»¬çš„ [news_scraper_output.json](https://github.com/bright-cn/Google-News-Scraper/blob/main/google-news-api-scraper/data/news_scraper_output.json) æ–‡ä»¶ä¸­æ‰¾åˆ°å®Œæ•´çš„ç¤ºä¾‹è¾“å‡ºã€‚

### å¯ç›´æ¥ä½¿ç”¨çš„ Python ä»£ç 
ä¸‹é¢æ˜¯ä¸€ä¸ªå¸®åŠ©æ‚¨å…¥é—¨çš„è„šæœ¬ç¤ºä¾‹ï¼š
```python
import requests
import json
import time


class BrightDataNews:
    def __init__(self, api_token):
        self.api_token = api_token
        self.headers = {
            "Authorization": f"Bearer {api_token}",
            "Content-Type": "application/json",
        }
        self.dataset_id = "gd_lnsxoxzi1omrwnka5r"

    def collect_news(self, search_queries):
        """
        Collect Google News articles using BrightData API
        """
        # 1. Trigger data collection
        print("Starting news collection...")
        trigger_response = self._trigger_collection(search_queries)
        snapshot_id = trigger_response.get("snapshot_id")
        print(f"Snapshot ID: {snapshot_id}")

        # 2. Wait for data to be ready
        print("Waiting for data...")
        while True:
            status = self._check_status(snapshot_id)
            print(f"Status: {status}")

            if status == "ready":
                # Check if data is actually available
                data = self._get_data(snapshot_id)
                if data and len(data) > 0:
                    break
            time.sleep(10)  # Wait 10 seconds before next check
        # 3. Get and save the data
        print("Saving data...")
        filename = f"news_scraper_output.json"
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        print(f"âœ“ Data saved to {filename}")
        print(f"âœ“ Collected {len(data)} news articles")
        return data

    def _trigger_collection(self, search_queries):
        """Trigger news data collection"""
        response = requests.post(
            "https://api.brightdata.com/datasets/v3/trigger",
            headers=self.headers,
            params={"dataset_id": self.dataset_id, "include_errors": "true"},
            json=search_queries,
        )
        return response.json()

    def _check_status(self, snapshot_id):
        """Check collection status"""
        response = requests.get(
            f"https://api.brightdata.com/datasets/v3/progress/{snapshot_id}",
            headers=self.headers,
        )
        return response.json().get("status")

    def _get_data(self, snapshot_id):
        """Get collected data"""
        response = requests.get(
            f"https://api.brightdata.com/datasets/v3/snapshot/{snapshot_id}",
            headers=self.headers,
            params={"format": "json"},
        )
        return response.json()
```
ä¸‹é¢æ˜¯ä½¿ç”¨æ–¹æ³•ï¼š
```python
# Initialize the client
news_client = BrightDataNews("<YOUR_API_TOKEN>")

# Define what you want to collect
queries = [
    {
        "url": "https://news.google.com/",
        "keyword": "artificial intelligence startups",
        "country": "US",
        "language": "en",
    },
    {
        "url": "https://news.google.com/",
        "keyword": "tech industry layoffs",
        "country": "US",
        "language": "en",
    },
]

# Start collection
try:
    news_data = news_client.collect_news(queries)
    print(f"Successfully collected {len(news_data)} articles")
except Exception as e:
    print(f"Collection failed: {str(e)}")
```
### ç†è§£ API çš„å®ç°æ–¹å¼
1. **è®¾ç½®æ‚¨çš„ API Token**
    - é¦–å…ˆï¼Œæ‚¨éœ€è¦ä¸€ä¸ª API token
    - å¦‚æœæ‚¨è¿˜æ²¡æœ‰ï¼Œè¯·æŸ¥çœ‹æˆ‘ä»¬çš„[è®¾ç½®æŒ‡å—](https://github.com/bright-cn/Google-News-Scraper/blob/main/google_news_api_setup.md)
2. **å¼€å§‹æ•°æ®é‡‡é›†**
    - å°†æœç´¢å‚æ•°ä¼ é€’ç»™ API
    - æ‚¨å°†è·å¾—ä¸€ä¸ª `snapshot_id`
3. **ç›‘æ§è¿›åº¦**
    - è¿™ä¸ªè¿‡ç¨‹éœ€è¦å‡ åˆ†é’Ÿ
    - æˆ‘ä»¬çš„ä»£ç ä¼šè‡ªåŠ¨æ£€æŸ¥çŠ¶æ€ï¼š
      - "running" = ä»åœ¨æ”¶é›†æ•°æ®
      - "ready" = å¯ä»¥æå–ç»“æœäº†ï¼
4. **è·å–æ•°æ®**
    - ä¸€æ—¦çŠ¶æ€ä¸º "ready"ï¼Œæˆ‘ä»¬å°±ä¼šæå–å¹¶ä¿å­˜æ‚¨çš„ç»“æœ
    - æ•°æ®ä»¥æ•´æ´çš„ JSON æ ¼å¼æä¾›
    - æ¯ç¯‡æ–‡ç« éƒ½åŒ…å«æˆ‘ä»¬ä¹‹å‰è®¨è®ºè¿‡çš„æ‰€æœ‰å­—æ®µ

## å®šåˆ¶æ‚¨çš„æ•°æ®é‡‡é›†
æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‚æ•°æ¥å¾®è°ƒæ‚¨çš„ç»“æœï¼š
| **å‚æ•°**            | **ç±»å‹**   | **æè¿°**                                                    | **ç¤ºä¾‹**                   |
|---------------------|------------|-------------------------------------------------------------|----------------------------|
| `limit`             | `integer`  | æ¯ä¸ªè¾“å…¥çš„æœ€å¤§è¿”å›ç»“æœæ•°                                    | `limit=10`                |
| `include_errors`    | `boolean`  | è·å–æ•…éšœæŠ¥å‘Šä»¥ä¾¿è¿›è¡Œé—®é¢˜æ’æŸ¥                                | `include_errors=true`     |
| `notify`            | `url`      | ä»»åŠ¡å®Œæˆæ—¶é€šçŸ¥çš„ Webhook URL                                 | `notify=https://notify-me.com/` |
| `format`            | `enum`     | è¾“å‡ºæ ¼å¼ï¼ˆå¦‚ JSONã€NDJSONã€JSONLã€CSVï¼‰                     | `format=json`             |

ğŸ’¡ **ä¸“ä¸šæç¤ºï¼š** æ‚¨è¿˜å¯ä»¥é€‰æ‹©å°†æ•°æ®[ä¼ é€åˆ°å¤–éƒ¨å­˜å‚¨](https://docs.brightdata.com/scraping-automation/web-data-apis/web-scraper-api/overview#via-deliver-to-external-storage)æˆ–é€šè¿‡[Webhook](https://docs.bright.cn/scraping-automation/web-data-apis/web-scraper-api/overview#via-webhook)ä¼ é€ã€‚

----

éœ€è¦æ›´å¤šç»†èŠ‚ï¼Ÿè¯·æŸ¥çœ‹[å®˜æ–¹ API æ–‡æ¡£](https://docs.brightdata.com/scraping-automation/web-data-apis/web-scraper-api/overview)ã€‚
